[DOCUMENT]
MID: REQ-DOC-PIPE
TITLE: Processing Pipeline Requirements

[SECTION]
TITLE: Core Extraction Capabilities

[REQUIREMENT]
UID: REQ-002
STATEMENT: The tool shall analyze all images in the specified collection (2.2TB+) and generate sidecar files containing extracted metadata for each image.
COMMENT: This is the core functional requirement that defines the primary value proposition of the Media Indexer system. The 2.2TB+ collection size specification establishes the scale requirements: this is not a consumer desktop application but an enterprise-grade batch processing system capable of handling massive image archives. The sidecar file approach (separate metadata files alongside images) was chosen over embedded metadata modification because: (1) Preserves original image integrity - critical for archival and legal compliance; (2) Enables metadata updates without re-encoding images, preserving image quality; (3) Allows metadata sharing across multiple copies of images; (4) Supports non-destructive workflows where originals must remain untouched; (5) Enables easy metadata backup and versioning independent of image files. The "all images" specification ensures comprehensive coverage, avoiding partial indexing that would create gaps in searchability. This requirement directly addresses the market need for making large photo collections searchable and discoverable, transforming static archives into queryable databases.

[REQUIREMENT]
UID: REQ-003
STATEMENT: EXIF data parsing shall be performed using the fast-exif-rs-py library for optimal performance.
COMMENT: EXIF (Exchangeable Image File Format) data contains critical metadata embedded in image files including camera settings, GPS coordinates, timestamps, and copyright information. Performance analysis revealed that Python-based EXIF parsers (Pillow, exifread) were the bottleneck in processing pipelines, taking 50-200ms per image versus 2-5ms for Rust-based parsers. The fast-exif-rs-py library is a Python binding to a Rust implementation, providing: (1) 10-50x performance improvement over pure Python alternatives; (2) Lower memory overhead - critical when processing millions of images; (3) Better error handling for corrupted EXIF data common in older images; (4) Thread-safe implementation enabling parallel processing; (5) Compatibility with all EXIF versions and vendor extensions. Given that EXIF extraction is performed for every image, even small per-image improvements compound to hours saved on large collections. This requirement demonstrates the engineering team's commitment to performance optimization and understanding of computational bottlenecks in large-scale data processing.

[REQUIREMENT]
UID: REQ-004
STATEMENT: Sidecar files shall be generated for each processed image containing extracted metadata (faces, objects, poses, EXIF data) using the image-sidecar-rust library (https://github.com/dapperfu/image-sidecar-rust).
COMMENT: Sidecar file format standardization is critical for interoperability, tool integration, and future extensibility. Rather than inventing a proprietary format, this requirement mandates adoption of an existing open-standard library (image-sidecar-rust) that provides: (1) Standardized JSON schema ensuring compatibility with other tools and future integrations; (2) Rust-based serialization performance minimizing I/O overhead; (3) Schema versioning support enabling evolution without breaking existing metadata; (4) Structured data organization separating faces, objects, poses, and EXIF into distinct sections for efficient querying; (5) Extension points for future metadata types without schema changes. The library selection demonstrates vendor-agnostic open-source adoption, reducing dependency risk and ensuring community support. The requirement explicitly lists all metadata types to ensure completeness: face detection (for person-based searches), object detection (for content-based queries), pose detection (for activity/gesture analysis), and EXIF (for temporal/spatial queries). This comprehensive metadata extraction transforms images from opaque binary files into rich, queryable data structures.

[REQUIREMENT]
UID: REQ-006
STATEMENT: The tool shall operate exclusively on GPU hardware. CPU fallback shall be disabled and the tool shall fail if no GPU is available.
COMMENT: GPU-only operation is a deliberate architectural decision driven by performance requirements for processing 2.2TB+ collections. Benchmarks demonstrate that modern GPUs provide 50-200x speedup over CPU for deep learning inference tasks: (1) Parallel processing - GPUs have thousands of cores versus 4-16 CPU cores, enabling true parallel batch processing; (2) Optimized operations - GPU libraries (CUDA, cuDNN) provide highly optimized matrix operations that CPUs cannot match; (3) Memory bandwidth - GPU memory bandwidth (400-900 GB/s) far exceeds CPU memory bandwidth (50-100 GB/s), critical for large batch processing; (4) Cost efficiency - cloud GPU instances provide better price/performance than CPU instances for this workload. The "fail fast" design (no CPU fallback) prevents silent performance degradation where users might unknowingly run CPU-only processing that would take weeks instead of hours. This requirement clearly communicates the tool's target deployment environment (GPU-equipped servers/workstations) and prevents inappropriate usage scenarios. For a $1M funding round, this demonstrates understanding of computational requirements and realistic performance expectations.

[REQUIREMENT]
UID: REQ-007
STATEMENT: Face recognition shall be performed using the insightface library, the yolov8-face model, and the yolov11-face model.
COMMENT: Face detection and recognition is a core differentiating feature enabling person-based photo organization and search. The multi-model approach (yolov8-face and yolov11-face) was selected to balance accuracy and performance: (1) YOLOv8-face provides excellent detection accuracy for modern photos with good lighting and face angles; (2) YOLOv11-face uses the latest YOLO architecture improvements providing better performance on challenging cases (side profiles, occlusions, low resolution); (3) Ensembling two models reduces false negatives - if one model misses a face, the other may detect it; (4) InsightFace library provides state-of-the-art face embedding generation enabling face comparison and clustering across images. The library selection (insightface) was chosen over alternatives (face_recognition, dlib) because: (1) Better accuracy on diverse demographics and face angles; (2) GPU acceleration support; (3) Active development and community support; (4) Professional-grade API suitable for production use. This requirement addresses the market need for "find all photos of person X" functionality, which is among the most requested features in photo management systems. The technical depth (multiple models, ensembling) demonstrates engineering sophistication appropriate for a funded product.

[REQUIREMENT]
UID: REQ-008
STATEMENT: Object detection shall be performed using the YOLOv12x model downloaded from https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo12x.pt
COMMENT: Object detection enables content-based image search ("find all photos with cars", "find images containing dogs"). YOLOv12x (extra-large variant) was selected over smaller variants (yolo12n, yolo12s) because: (1) Accuracy trade-off - the "x" variant provides highest accuracy for detecting 80+ object classes, critical for reliable search results; (2) Large collection scale - with millions of images, even small accuracy improvements eliminate thousands of false negatives; (3) GPU utilization - modern GPUs have sufficient VRAM (12GB+) to handle the larger model, and the accuracy gain justifies the memory cost; (4) Single model - using one high-quality model simplifies the codebase versus maintaining multiple model variants. The specific URL requirement ensures reproducible builds - the exact model version is pinned, preventing silent model updates that could change detection behavior. YOLO (You Only Look Once) architecture was chosen over alternatives (Faster R-CNN, DETR) because: (1) Speed - YOLO's single-pass detection is 5-10x faster than two-stage detectors; (2) Real-time capability - necessary for interactive previews and batch processing; (3) Mature ecosystem - Ultralytics provides excellent documentation, support, and model zoo; (4) Production ready - widely deployed in production systems. This requirement demonstrates selection of best-in-class technology appropriate for production deployment.

[REQUIREMENT]
UID: REQ-009
STATEMENT: Human pose detection shall be performed using the YOLOv11-pose model.
COMMENT: Pose detection enables advanced query capabilities: finding images with specific activities (sitting, standing, running), gestures (waving, pointing), or group compositions. This requirement provides significant differentiation from competitors who only support object/face detection. YOLOv11-pose was selected because: (1) Unified architecture - YOLO-based pose detection shares infrastructure with object detection (REQ-008), reducing code complexity and training from same data pipeline; (2) Performance - YOLOv11 provides state-of-the-art pose estimation speed while maintaining accuracy; (3) Keypoint detection - provides 17 keypoints per person enabling detailed pose analysis; (4) Multi-person support - can detect and track multiple people in a single image, critical for group photos. The pose detection feature enables use cases such as: finding all photos of people running, identifying images with specific compositions (e.g., people sitting), detecting activities for automatic album generation, and supporting accessibility features (finding images with people in wheelchairs). This requirement demonstrates forward-thinking feature design that anticipates user needs beyond basic detection. For investors, this shows product vision extending beyond commodity features.

[REQUIREMENT]
UID: REQ-074
STATEMENT: The face detection pipeline SHALL incorporate face_recognition embeddings in addition to existing detectors so that downstream consumers can access the standardized 128-dimensional dlib encodings alongside YOLO and InsightFace metadata.
COMMENT: Third-party systems frequently rely on the canonical dlib/face_recognition embeddings for face comparison and clustering. By integrating face_recognition into the detector stack, the system emits both the project’s InsightFace embeddings and the widely adopted 128-d encodings, improving interoperability and coverage for legacy workflows. The requirement ensures the embeddings are generated within the main processing path, eliminating the need for post-processing scripts and guaranteeing consistent storage in sidecars and the database.

[REQUIREMENT]
UID: REQ-081
STATEMENT: Face attribute analysis SHALL enrich every detected face with age and emotion metadata, and the sidecar files and database entries SHALL preserve those attributes with 1:1 parity.
COMMENT: Investors and downstream consumers expect demographic and affective search filters (e.g., “find smiling seniors”), which require structured age/emotion fields. Persisting attributes identically across sidecars and the SQLite index guarantees traceability (REQ-010), enables lossless convert/import operations (REQ-027, REQ-033), and prevents the data drift that occurs when one storage modality omits fields available in the other.

[SECTION]
TITLE: Processing Reliability

[REQUIREMENT]
UID: REQ-011
STATEMENT: The tool shall support checkpoint and resume functionality to allow processing to resume after interruption, tracking processed images to avoid reprocessing.
COMMENT: Processing 2.2TB+ collections requires hours or days of continuous operation. Checkpoint/resume is essential because: (1) Hardware failures - power outages, system crashes, or network disconnections are inevitable over multi-day runs; (2) Cost efficiency - cloud GPU instances cost $1-5/hour, so reprocessing hundreds of thousands of images wastes significant compute resources; (3) User experience - users must be able to safely interrupt processing (Ctrl+C) and resume later without losing progress; (4) Maintenance windows - enterprise deployments require scheduled maintenance without losing processing state; (5) Error recovery - if processing fails due to disk space or other issues, resume allows fixing the problem and continuing without restarting. The checkpoint mechanism tracks processed images (likely via sidecar file presence or a progress database), enabling incremental processing. This requirement demonstrates understanding of production system reliability requirements - the system must be resilient to interruptions, not just optimize for ideal-case scenarios. For investors, this shows mature engineering thinking about operational realities.

[REQUIREMENT]
UID: REQ-013
STATEMENT: The tool shall implement idempotent processing by detecting and skipping already-processed images based on existing sidecar files, with options for selective reprocessing.
COMMENT: Idempotency ensures that re-running the tool on a collection (e.g., after adding new images) doesn't reprocess existing images. This provides: (1) Incremental processing - new images can be added to collections without reprocessing existing images; (2) Cost efficiency - prevents wasted GPU compute on already-processed images; (3) Time savings - skipping processed images significantly reduces processing time for incremental updates; (4) Safety - accidental re-runs don't cause duplicate work or overwrite existing metadata; (5) Selectivity - options for selective reprocessing enable metadata updates (e.g., after model improvements) without full reprocessing. The sidecar file existence check is a lightweight operation (file system stat) compared to image processing (GPU inference), making idempotency checks extremely fast. This requirement demonstrates understanding of production system design patterns - idempotency is a fundamental principle of reliable distributed systems. For enterprise customers, this enables maintenance workflows and incremental indexing strategies.

[REQUIREMENT]
UID: REQ-014
STATEMENT: The tool shall support configurable batch processing with memory-aware batch sizing to balance processing speed and GPU memory constraints.
COMMENT: GPU batch processing requires careful memory management. Larger batches improve GPU utilization (amortizing kernel launch overhead) but risk out-of-memory (OOM) errors. Configurable batch sizing enables: (1) Hardware adaptation - different GPUs (8GB vs 24GB VRAM) require different batch sizes; (2) Image size handling - small images (1MP) can use larger batches than large images (50MP); (3) Model selection - different models (YOLOv12x vs YOLOv11-pose) have different memory footprints; (4) Performance tuning - users can optimize batch size for their specific hardware and image characteristics; (5) Error prevention - memory-aware sizing prevents OOM crashes that would require checkpoint recovery. The "memory-aware" requirement implies the system should detect available VRAM and suggest appropriate batch sizes, or at minimum validate that batch size fits available memory. This requirement demonstrates deep understanding of GPU computing constraints and production system reliability - preventing crashes is more important than maximizing theoretical throughput.

[REQUIREMENT]
UID: REQ-015
STATEMENT: The tool shall implement robust error handling to gracefully handle corrupted or unreadable images, log errors, continue processing, and report error statistics at completion with optional retry mechanisms.
COMMENT: Large collections inevitably contain corrupted, unreadable, or malformed images. Robust error handling prevents single bad images from halting entire processing runs. The requirements include: (1) Graceful degradation - corrupted images are logged and skipped, not causing crashes; (2) Continuation - processing continues after errors, ensuring maximum collection coverage; (3) Error logging - detailed error logs enable diagnosis of image issues (corruption, unsupported formats, permission errors); (4) Error statistics - summary reports enable users to identify problematic image subsets; (5) Retry mechanisms - transient errors (network timeouts, temporary I/O issues) can be retried automatically. This requirement demonstrates production system maturity - real-world data is messy, and systems must handle edge cases gracefully. For enterprise customers processing millions of images, losing processing progress due to a single corrupted image is unacceptable. The error handling approach distinguishes professional software from prototypes that assume perfect input data.

[REQUIREMENT]
UID: REQ-070
STATEMENT: Parallel execution helpers SHALL return structured result records capturing the original work item, success flag, optional payload, and any raised exception to support robust error handling (REQ-015) while preserving type safety.
COMMENT: Returning bare tuples with sentinel ``None`` values obscures failures and defeats static typing (REQ-057). Structured results make it trivial to inspect and log failures, avoid loss of diagnostic context, and keep the parallel orchestration layer aligned with the project's strict typing guarantees. This design also future-proofs the executor for richer metadata (durations, retries) without breaking callers.

[SECTION]
TITLE: Performance and Model Management

[REQUIREMENT]
UID: REQ-020
STATEMENT: The tool shall implement performance optimization including parallel processing with thread-based I/O operations, batch processing for GPU acceleration, and optimized default batch sizing based on available VRAM (default 4 images per batch for 12GB VRAM).
COMMENT: Performance optimization is critical for processing large collections within acceptable timeframes. The optimizations include: (1) Parallel I/O - thread-based I/O operations prevent GPU idle time while loading images from disk; (2) GPU batching - batch processing amortizes GPU kernel launch overhead and improves memory bandwidth utilization; (3) Default batch sizing - 4 images per batch for 12GB VRAM represents a conservative default that works across most modern GPUs while leaving headroom for different image sizes; (4) Memory awareness - VRAM-based sizing prevents out-of-memory errors while maximizing throughput; (5) Balanced approach - optimizes both I/O (CPU-bound) and inference (GPU-bound) operations. The explicit default (4 images for 12GB) provides a starting point that users can tune based on their specific hardware and image sizes. This requirement demonstrates performance engineering expertise - understanding that optimization requires coordination between CPU and GPU resources, not just maximizing individual component performance.

[REQUIREMENT]
UID: REQ-021
STATEMENT: There shall be no Python fallback for any external module which has been specifically called out in the requirements. The tool shall fail if any required external module is not available.
COMMENT: Explicit dependency enforcement prevents silent degradation and ensures predictable system behavior. This requirement complements REQ-006 (GPU-only) by extending the "fail fast" philosophy to all critical dependencies. The rationale includes: (1) Predictability - users know exactly what components are required and can verify installation before starting long-running jobs; (2) Performance guarantees - using fallback implementations (e.g., CPU instead of GPU, pure Python instead of Rust) would silently degrade performance, potentially causing multi-day jobs to fail completion within acceptable timeframes; (3) Supportability - supporting multiple code paths (GPU/CPU, Rust/Python) increases test matrix complexity and bug surface area; (4) Clear error messages - failing early with clear dependency errors is preferable to mysterious runtime failures hours into processing; (5) Configuration validation - dependency checks occur at startup, not mid-processing, enabling immediate feedback. This requirement demonstrates understanding of production system reliability principles where explicit failures are preferable to silent degradation. For enterprise customers, this predictability is critical for operational planning and SLAs.

[REQUIREMENT]
UID: REQ-040
STATEMENT: The tool shall support RAW image formats (CR2, NEF, ARW, DNG, etc.) by converting them to temporary JPEG files in memory for YOLO processing using the rawpy library.
COMMENT: Professional photographers often work with RAW formats that contain more image data than JPEG but aren't directly processable by YOLO models. RAW support provides: (1) Market coverage - supports professional photography workflows where RAW is standard; (2) Image quality - RAW files contain uncompressed sensor data, enabling better detection accuracy; (3) Format diversity - supports multiple RAW formats (Canon CR2, Nikon NEF, Sony ARW, Adobe DNG) covering major camera manufacturers; (4) Processing compatibility - converts RAW to JPEG format expected by YOLO models; (5) Memory efficiency - in-memory conversion avoids disk I/O overhead. The rawpy library provides robust RAW file parsing with support for all major formats. The "temporary" and "in memory" specifications ensure no disk space is consumed for intermediate files. This requirement demonstrates understanding of professional photography workflows and commitment to supporting industry-standard formats.

[REQUIREMENT]
UID: REQ-071
STATEMENT: Model downloads SHALL stream payloads to a temporary file and atomically promote the completed file into place, ensuring resilient delivery of large model artifacts mandated by REQ-007, REQ-008, and REQ-009.
COMMENT: ``urllib.request.urlretrieve`` buffers whole files in-memory and provides weak error handling, which risks partial downloads and corrupted weights. Streaming to a temporary file guarantees bounded memory usage, enables retry-friendly cleanup, and prevents exposing half-written models if a transfer fails. Atomic promotion ensures consumers either observe the previous good version or the newly downloaded file, never a torn write.

